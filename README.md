# Textual-Data-Extraction-and-Analysis-for-Article-Texts-with-NLP
This project aims to extract textual data from given URLs, specifically focusing on article texts, and perform text analysis to compute various linguistic variables
## Summary:
This project aims to extract textual data from given URLs, specifically focusing on article texts, and perform text analysis to compute various linguistic variables. The process involves data extraction using Python programming with libraries such as BeautifulSoup, Selenium, or Scrapy, followed by text analysis to calculate variables defined in the "Text Analysis.docx" file. The extracted data and analysis results are structured and saved according to the provided input and output structure files.

## Approach:

1. **Data Extraction: Python programming will be utilized along with web scraping libraries like BeautifulSoup or Selenium to extract article texts from the provided URLs. Only the article title and text will be extracted, excluding any website headers, footers, or irrelevant content.**

2. **Text Analysis: After data extraction, textual analysis will be performed on each extracted article. Various linguistic variables such as positive score, negative score, polarity score, subjectivity score, average sentence length, etc., will be computed using libraries like TextBlob, NLTK, and textstat.**

3. Output Structure: The analysis results will be organized and saved in an Excel file following the format specified in the "Output Data Structure.xlsx" file. This ensures that the output aligns with the required structure and contains all necessary variables.


# Dependencies:

**Python (3.x recommended)**
**BeautifulSoup (for web scraping)**
**TextBlob (for sentiment analysis)**
**NLTK (Natural Language Toolkit)**
**textstat (for text analysis)**
